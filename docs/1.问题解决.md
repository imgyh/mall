# renren-fast引入nacos报错

现象: 将renren-fast中的springboot升至2.6.11, 新增Spring Cloud Alibaba:2021.0.4.0, Spring Cloud:2021.0.4. 之后引入nacos注册中心与配置中心

```
<!-- nacos 服务注册 -->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
<!-- nacos 配置中心 -->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-bootstrap</artifactId>
</dependency>
```

报错如下:

```
java.lang.NoSuchMethodError: com.google.common.collect.Sets$SetView.iterator()Lcom/google/common/collect/UnmodifiableIterator;
```

依赖包冲突. 下载一个Maven helper插件发现guava包含在`spring-cloud-starter-alibaba-nacos-discovery`和`springfox-swagger2`中；将18版本的排除, 使用nacos依赖的guava20版本. (**问题不是在这儿**)

使用Maven helper插件发现commons-codec也冲突，将原来的commons-codec1.10升至1.15, nacos依赖了1.15版本

再次报错:

```
org.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is java.lang.NullPointerException
```

解决办法: https://blog.csdn.net/hadues/article/details/123753888

swagger版本从2.7.0 到 2.9.2, 2.9.2版本本身就是使用guava20版本, 上面那个排除guava20就不要了

application.yml添加

```
spring:
  mvc:
    pathmatch:
      matching-strategy: ANT_PATH_MATCHER
```



并在SwaggerConfig类中添加如下代码:

```
/**
 * Copyright (c) 2016-2019 人人开源 All rights reserved.
 *
 * https://www.renren.io
 *
 * 版权所有，侵权必究！
 */

package io.renren.config;

import io.swagger.annotations.ApiOperation;
import org.springframework.boot.actuate.autoconfigure.endpoint.web.CorsEndpointProperties;
import org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties;
import org.springframework.boot.actuate.autoconfigure.web.server.ManagementPortType;
import org.springframework.boot.actuate.endpoint.ExposableEndpoint;
import org.springframework.boot.actuate.endpoint.web.*;
import org.springframework.boot.actuate.endpoint.web.annotation.ControllerEndpointsSupplier;
import org.springframework.boot.actuate.endpoint.web.annotation.ServletEndpointsSupplier;
import org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;
import org.springframework.util.StringUtils;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;
import springfox.documentation.builders.ApiInfoBuilder;
import springfox.documentation.builders.PathSelectors;
import springfox.documentation.builders.RequestHandlerSelectors;
import springfox.documentation.service.ApiInfo;
import springfox.documentation.service.ApiKey;
import springfox.documentation.spi.DocumentationType;
import springfox.documentation.spring.web.plugins.Docket;
import springfox.documentation.swagger2.annotations.EnableSwagger2;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

import static com.google.common.collect.Lists.newArrayList;

@Configuration
@EnableSwagger2
public class SwaggerConfig implements WebMvcConfigurer {

    @Bean
    public Docket createRestApi() {
        return new Docket(DocumentationType.SWAGGER_2)
            .apiInfo(apiInfo())
            .select()
            //加了ApiOperation注解的类，才生成接口文档
            .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class))
            //包下的类，才生成接口文档
            //.apis(RequestHandlerSelectors.basePackage("io.renren.controller"))
            .paths(PathSelectors.any())
            .build()
            .securitySchemes(security());
    }

    private ApiInfo apiInfo() {
        return new ApiInfoBuilder()
            .title("人人开源")
            .description("renren-fast文档")
            .termsOfServiceUrl("https://www.renren.io")
            .version("3.0.0")
            .build();
    }

    private List<ApiKey> security() {
        return newArrayList(
            new ApiKey("token", "token", "header")
        );
    }

    /**
     * 增加如下配置可解决Spring Boot 2.6.11 与Swagger2 2.9.2 不兼容问题
     **/
    @Bean
    public WebMvcEndpointHandlerMapping webEndpointServletHandlerMapping(WebEndpointsSupplier webEndpointsSupplier, ServletEndpointsSupplier servletEndpointsSupplier, ControllerEndpointsSupplier controllerEndpointsSupplier, EndpointMediaTypes endpointMediaTypes, CorsEndpointProperties corsProperties, WebEndpointProperties webEndpointProperties, Environment environment) {
        List<ExposableEndpoint<?>> allEndpoints = new ArrayList();
        Collection<ExposableWebEndpoint> webEndpoints = webEndpointsSupplier.getEndpoints();
        allEndpoints.addAll(webEndpoints);
        allEndpoints.addAll(servletEndpointsSupplier.getEndpoints());
        allEndpoints.addAll(controllerEndpointsSupplier.getEndpoints());
        String basePath = webEndpointProperties.getBasePath();
        EndpointMapping endpointMapping = new EndpointMapping(basePath);
        boolean shouldRegisterLinksMapping = this.shouldRegisterLinksMapping(webEndpointProperties, environment, basePath);
        return new WebMvcEndpointHandlerMapping(endpointMapping, webEndpoints, endpointMediaTypes, corsProperties.toCorsConfiguration(), new EndpointLinksResolver(allEndpoints, basePath), shouldRegisterLinksMapping, null);
    }
    private boolean shouldRegisterLinksMapping(WebEndpointProperties webEndpointProperties, Environment environment, String basePath) {
        return webEndpointProperties.getDiscovery().isEnabled() && (StringUtils.hasText(basePath) || ManagementPortType.get(environment).equals(ManagementPortType.DIFFERENT));
    }

}
```



# 后台解决跨域

![](./images/20230218204150.png)

![](./images/20230218204246.png)

![](./images/20230218204410.png)

![](./images/20230218204519.png)

我们使用gateway做网关, 所有请求发送到网关, 网关再转给各个微服务, renren-fast也作为一个微服务. 我们在网关处解决跨域, renren-fast里面有跨域配置，需要注释掉. 

跨域解决参考: https://blog.csdn.net/qq_24052051/article/details/127438027

Spring套件版本符合Spring Cloud Alibaba目前最新的版本建议要求：

- Springboot版本：2.6.11
- Sping Cloud版本：2021.0.4
- Spring Cloud Alibaba版本：2021.0.4.0
- Gateway版本：3.4.1

```
spring:
  cloud:
    gateway:
      #跨域处理，需要关闭具体微服务上的跨域设置，否则此设置无效
      globalcors: # 全局的跨域配置
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        # options请求 就是一种询问服务器是否浏览器可以跨域的请求
        # 如果每次跨域都有询问服务器是否浏览器可以跨域对性能也是损耗
        # 可以配置本次跨域检测的有效期maxAge
        # 在maxAge设置的时间范围内，不去询问，统统允许跨域
        corsConfigurations:
          '[/**]':
            allowedOriginPatterns: # 允许哪些网站的跨域请求
              - "*"
            allowedMethods: # 允许的跨域ajax的请求方式
              - "GET"
              - "POST"
              - "DELETE"
              - "PUT"
              - "OPTIONS"
            allowedHeaders: "*"    # 允许在请求中携带的头信息
            allowCredentials: true    # 允许在请求中携带cookie
            maxAge: 360000            # 本次跨域检测的有效期(单位毫秒)
            # 有效期内，跨域请求不会一直发option请求去增大服务器压力
      routes:
        - id: renren
          uri: lb://renren # lb 负载均衡 需要添加 spring-cloud-loadbalancer
          predicates:
            - Path=/api/**
          filters:
            - RewritePath=/api/?(?<segment>.*), /renren-fast/$\{segment}
```



# 说明

在此之后, 我们引入阿里云oss时出错，改成了以下版本.

|         组件         |    版本    |
| :------------------: | :--------: |
| Spring Cloud Alibaba | 2021.0.1.0 |
|     Spring Cloud     |  2021.0.1  |
|     Spring Boot      |   2.6.3    |
|        Nacos         |   1.4.2    |



# 逻辑删除

步骤 1: 配置com.baomidou.mybatisplus.core.config.GlobalConfig$DbConfig

- 例: application.yml

```yaml
mybatis-plus:
  global-config:
    db-config:
      logic-delete-field: flag # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以忽略不配置步骤2)
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
```

步骤 2: 实体类字段上加上`@TableLogic`注解

```java
@TableLogic
private Integer deleted;
```



#  JSR303校验

导入校验包

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-validation</artifactId>
</dependency>
```
1. 数据校验

  1)、给Bean添加校验注解:javax.validation.constraints，并定义自己的message提示 如：@NotBlank(message = "品牌名必须提交")

  2)、开启校验功能@Valid.  效果：校验错误以后会有默认的响应；

  3)、给校验的bean后紧跟一个BindingResult，就可以获取到校验的结果 public R save(@Valid @RequestBody BrandEntity brand,BindingResult result){}

2. 分组校验（多场景的复杂校验）

  1)、@NotBlank(message = "品牌名必须提交",groups = {AddGroup.class,UpdateGroup.class}给校验注解标注什么情况需要进行校验

  2)、使用@Validated({AddGroup.class}). public R save(@Validated(AddGroup.class) @RequestBody BrandEntity brand){}

  3)、默认没有指定分组的校验注解@NotBlank，在分组校验情况@Validated({AddGroup.class})下不生效，只会在@Validated生效；

  4)、定义空接口AddGroup.class作为groups的值，起到标记作用就行了

3. 自定义校验

   1)、编写一个自定义的校验注解

   ```
   package com.imgyh.mall.product.valid;
   
   import javax.validation.Constraint;
   import javax.validation.Payload;
   import java.lang.annotation.Documented;
   import java.lang.annotation.Retention;
   import java.lang.annotation.Target;
   
   import static java.lang.annotation.ElementType.*;
   import static java.lang.annotation.RetentionPolicy.RUNTIME;
   
   /**
    * @ClassName : ListValue
    * @Package : com.imgyh.mall.product.valid
    * @Description :
    * @Author : imgyh
    * @Mail : admin@imgyh.com
    * @Github : https://github.com/imgyh
    * @Site : https://www.imgyh.com
    * @Date : 2023/2/26 17:23
    * @Version : v1.0
    * @ChangeLog :
    * * * * * * * * * * * * * * * * * * * * * * * *
    * <p>
    * * * * * * * * * * * * * * * * * * * * * * * *
    **/
   
   @Documented
   // 使用哪些校验器校验
   @Constraint(validatedBy = { ListValueConstraintValidator.class })
   @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })
   @Retention(RUNTIME)
   public @interface ListValue {
       // 校验失败的提示信息去哪儿取 需要把提示信息写到 ValidationMessages.properties
       String message() default "{com.imgyh.mall.product.valid.ListValue.message}";
   
       Class<?>[] groups() default {};
   
       Class<? extends Payload>[] payload() default {};
   
       int[] vals() default { };
   }
   
   ```

   

   2)、编写一个自定义的校验器 ConstraintValidator

   ```
   package com.imgyh.mall.product.valid;
   
   import javax.validation.ConstraintValidator;
   import javax.validation.ConstraintValidatorContext;
   import java.util.HashSet;
   
   /**
    * @ClassName : ListValueConstraintValidator
    * @Package : com.imgyh.mall.product.valid
    * @Description :
    * @Author : imgyh
    * @Mail : admin@imgyh.com
    * @Github : https://github.com/imgyh
    * @Site : https://www.imgyh.com
    * @Date : 2023/2/26 17:29
    * @Version : v1.0
    * @ChangeLog :
    * * * * * * * * * * * * * * * * * * * * * * * *
    * <p>
    * * * * * * * * * * * * * * * * * * * * * * * *
    **/
   // ConstraintValidator<A, T> A 校验的注解 T注解里面值的类型
   public class ListValueConstraintValidator implements ConstraintValidator<ListValue, Integer> {
       HashSet<Integer> set = new HashSet<>();
       // 初始化方法
       @Override
       public void initialize(ListValue constraintAnnotation) {
   
           for (int val : constraintAnnotation.vals()) {
               set.add(val);
           }
       }
   
       // 判断是否校验成功
       @Override
       public boolean isValid(Integer integer, ConstraintValidatorContext constraintValidatorContext) {
           return set.contains(integer);
       }
   }
   
   ```

   

   3)、ValidationMessages.properties

   ```
   com.imgyh.mall.product.valid.ListValue.message=必须提交指定值
   ```

   4)、使用自定义校验注解

   ```
   @ListValue(vals = {0,1}, groups = {AddGroup.class, UpdateStatusGroup.class})
   private Integer showStatus;
   ```

   

# 统一异常处理

1）、编写异常处理类，使用@ControllerAdvice、@RestControllerAdvice。

2）、使用@ExceptionHandler标注方法可以处理的异常。

```
package com.imgyh.mall.product.exception;

import com.imgyh.mall.common.exception.BizCodeEnume;
import com.imgyh.mall.common.utils.R;
import org.springframework.web.bind.MethodArgumentNotValidException;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.RestControllerAdvice;

import java.util.HashMap;
import java.util.Map;

/**
 * @ClassName : ProductExecptionAdvice
 * @Package : com.imgyh.mall.product.exception
 * @Description :
 * @Author : imgyh
 * @Mail : admin@imgyh.com
 * @Github : https://github.com/imgyh
 * @Site : https://www.imgyh.com
 * @Date : 2023/2/26 16:26
 * @Version : v1.0
 * @ChangeLog
 * * * * * * * * * * * * * * * * * * * * * * * *
 * <p>
 * * * * * * * * * * * * * * * * * * * * * * * *
 **/
@RestControllerAdvice(basePackages = "com.imgyh.mall.product.app")
public class ProductExceptionAdvice {

    // 使用@ExceptionHandler标注方法可以处理的异常
    @ExceptionHandler(value = MethodArgumentNotValidException.class)
    public R handleVaildException(MethodArgumentNotValidException e){
        Map<String, String> map = new HashMap<>();
        //1、获取校验的错误结果
        e.getFieldErrors().forEach((item) -> {
            //FieldError 获取到错误提示
            String message = item.getDefaultMessage();
            //获取错误的属性的名字
            String field = item.getField();
            map.put(field, message);
        });

        return R.error(BizCodeEnume.VAILD_EXCEPTION.getCode(), BizCodeEnume.VAILD_EXCEPTION.getMsg()).put("data", map);
    }

    @ExceptionHandler(value = Throwable.class)
    public R handleException(Throwable e){

        return R.error(BizCodeEnume.UNKNOW_EXCEPTION.getCode(), BizCodeEnume.UNKNOW_EXCEPTION.getMsg());
    }
}

```

# MybatisPlus分页插件

```
package com.imgyh.mall.product.config;

import com.baomidou.mybatisplus.annotation.DbType;
import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;
import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;
import org.mybatis.spring.annotation.MapperScan;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.transaction.annotation.EnableTransactionManagement;

/**
 * @ClassName : MybatisPlusConfig
 * @Package : com.imgyh.mall.product.config
 * @Description :
 * @Author : imgyh
 * @Mail : admin@imgyh.com
 * @Github : https://github.com/imgyh
 * @Site : https://www.imgyh.com
 * @Date : 2023/2/27 15:51
 * @Version : v1.0
 * @ChangeLog :
 * * * * * * * * * * * * * * * * * * * * * * * *
 * <p>
 * * * * * * * * * * * * * * * * * * * * * * * *
 **/
@Configuration
@EnableTransactionManagement //开启事务
@MapperScan("com.imgyh.mall.product.dao")
public class MybatisPlusConfig {
    // 添加分页拦截器
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() {
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor();
        paginationInnerInterceptor.setDbType(DbType.MYSQL);
        paginationInnerInterceptor.setOverflow(true);
        interceptor.addInnerInterceptor(paginationInnerInterceptor);
        return interceptor;
    }
}

```

# 首页性能压测

压测环境: i7 8700 + 8G + idea (gateway+product微服务) + WSL(Nginx) + Windows (MySQL+Nacos)

jmeter压测参数: 线程50+循环次数200

默认thymeleaf无缓存, MySQL无索引, 日志级别debug

| 压测内容                            | 压测线程数 | 吞吐量/s                | 90%响应时间ms | 95%响应时间ms | 99%响应时间ms |
| ----------------------------------- | ---------- | ----------------------- | ------------- | ------------- | ------------- |
| Nginx                               | 50         | 8818                    | 1             | 1             | 3             |
| Gateway                             | 50         | 5367                    | 7             | 12            | 36            |
| 简单服务(返回hello字符串)           | 50         | 9551                    | 1             | 1             | 3             |
| 首页渲染                            | 50         | 1243(db、thymeleaf瓶颈) | 57            | 76            | 141           |
| 首页渲染(加索引)                    | 50         | 1301(thymeleaf瓶颈)     | 59            | 78            | 118           |
| 首页渲染（开缓存、加索引）          | 50         | 2663                    | 24            | 31            | 51            |
| 首页渲染（开缓存、加索引、关日志）  | 50         | 3054                    | 14            | 24            | 74            |
| 三级分类接口                        | 50         | 360                     | 252           | 309           | 450           |
| 三级分类接口（加索引、关日志）      | 50         | 467                     | 215           | 268           | 413           |
| 三级分类接口（ 使用redis 作为缓存） | 50         | 2099                    | 26            | 35            | 85            |
| 首页全量数据获取                    | 50         | 卡死、静态资源太多      |               |               |               |
| 首页全量数据获取(动静分离)          | 50         | 11                      | 240           | 400           | 2632          |
| Nginx+Gateway                       | 50         |                         |               |               |               |
| Gateway+简单服务                    | 50         | 4793                    | 10            | 13            | 23            |
| Nginx+Gateway+简单服务              | 50         | 2258                    | 25            | 29            | 40            |

# Nginx动静分离

将所有静态文件打包放入nginx的html目录中并在配置文件中添加如下配置。以后所有带有/static的请求都会到这里来找

```nginx
location /static { # 静态资源
    root   /usr/share/nginx/html;
    # index  index.html index.htm;
}
```



![image-20230315192145836](images/image-20230315192145836.png)

完整配置:

```nginx
upstream mall{
    server  192.168.16.1:88; # gateway集群IP, 可配置多个实现负载均衡
}
server {
    listen       80;
    server_name  mall.gyh.im; # 自定义的域名

    #charset koi8-r;
    #access_log  /var/log/nginx/log/host.access.log  main;

    location /static { # 静态资源
        root   /usr/share/nginx/html;
        # index  index.html index.htm;
    }

    location / {
        # root   /usr/share/nginx/html;
        # index  index.html index.htm;
        proxy_set_header Host $host; # 将host这个header传给gateway, gateway才能根据这个host路由
        proxy_pass http://mall; # upstream 的名字, 负载均衡
    }

    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
```

# Redis缓存

为了系统性能的提升，我们一般都会将部分数据放入缓存中，加速访问。而db 承担数据落盘工作。

哪些数据适合放入缓存？

- 即时性、数据一致性要求不高的
- 访问量大且更新频率不高的数据（读多，写少）

举例：电商类应用，商品分类，商品列表等适合缓存并加一个失效时间(根据数据更新频率来定)，后台如果发布一个商品，买家需要5 分钟才能看到新的商品一般还是可以接受的。

注意：在开发中，凡是放入缓存中的数据我们都应该**指定过期时间**，使其可以在系统即使没有主动更新数据也能自动触发数据加载进缓存的流程。避免业务崩溃导致的数据永久不一致问题。

![image-20230315212322206](images/image-20230315212322206.png)

![image-20230315215546304](images/image-20230315215546304.png)

![image-20230315215559586](images/image-20230315215559586.png)

![image-20230315215612224](images/image-20230315215612224.png)

## 缓存穿透

缓存穿透是指查询**一个一定不存在的数据**，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的null 写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能DB 就挂掉了，要是有人利用不存在的key 频繁攻击我们的应用，这就是漏洞。

风险：**利用不存在的数据进行攻击**，数据库瞬时压力增大，最终导致崩溃

解决：**缓存空结果**、并且**设置短的过期时间**。

![image-20230315220500005](images/image-20230315220500005.png)

## 缓存雪崩

缓存雪崩是指在我们设置缓存时采用了**相同的过期时间**，导致缓存在**某一时刻同时失效**，请求全部转发到DB，DB 瞬时压力过重雪崩。

解决：原有的**失效时间基础上增加一个随机值**，比如1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

![image-20230315220943972](images/image-20230315220943972.png)

## 缓存击穿

对于一些设置了过期时间的key，如果这些key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。

这个时候，需要考虑一个问题：如果**这个key 在大量请求同时进来前正好失效**，那么所有对这个key 的数据查询都落到db，我们称为缓存击穿。

解决：**加锁** ，大量并发只让一个去查，其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db

![image-20230315221147419](images/image-20230315221147419.png)

## 锁时序问题

如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库

![image-20230316105502776](images/image-20230316105502776.png)



![image-20230316105138960](images/image-20230316105138960.png)



## 本地锁解决缓存击穿

分布式缓存逻辑:

```java
public Map<String, List<Catelog2Vo>> getCatalogJson() {
    /**
         * 1、空结果缓存：解决缓存穿透问题
         * 2、设置过期时间(加随机值)：解决缓存雪崩
         * 3、加锁：解决缓存击穿问题
         */
    // 1.先去redis中查有没有
    String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
    if (StringUtils.isEmpty(catalogJSON)){
        // 2. redis中没有就去数据库中查, 并存到redis中
        // 2.1. 无锁的情况
        // Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();
        // String s = JSON.toJSONString(catalogJsonFromDB);
        // redisTemplate.opsForValue().set("catalogJSON",s);
        // 2.2 本地锁
        // Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDBWithLocalLock();
        // 2.3 redis分布式锁
        // Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDBWithRedisLock();
        // 2.4 redisson分布式锁
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDBWithRedissonLock();

        return catalogJsonFromDB;
    }
    // 3. redis中有，转化为相应类型
    Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
    return map;
}
```



本地锁逻辑:

```java
/**
 * 本地锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithLocalLock() {
    //只要是同一把锁，就能锁住这个锁的所有线程
    //synchronized (this)：SpringBoot所有的组件在容器中都是单例的。
    //本地锁：synchronized，JUC（Lock),在分布式情况下，想要锁住所有，必须使用分布式锁
    synchronized (this){
        // 1. 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)){
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
            return map;
        }

        // 2. 查询数据库
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();

        // 3. 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON",s);
        return catalogJsonFromDB;
    }
}
```



查询数据库的代码:

```java
/**
 * 查询数据库, 并解析为相应的格式
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDB() {
    List<CategoryEntity> categoryEntities = this.list();
    List<CategoryEntity> l1 = categoryEntities.stream().filter(categoryEntity -> {
        return categoryEntity.getCatLevel() == 1;
    }).collect(Collectors.toList());

    Map<String, List<Catelog2Vo>> map = l1.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
        List<Catelog2Vo> list = categoryEntities.stream().filter(categoryEntity2 -> {
            return categoryEntity2.getCatLevel() == 2 && categoryEntity2.getParentCid() == v.getCatId();
        }).map(categoryEntity2 -> {
            Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), null, categoryEntity2.getCatId().toString(), categoryEntity2.getName());
            List<Catelog2Vo.Category3Vo> collect = categoryEntities.stream().filter(categoryEntity3 -> {
                return categoryEntity3.getCatLevel() == 3 && categoryEntity3.getParentCid() == categoryEntity2.getCatId();
            }).map(categoryEntity3 -> {
                Catelog2Vo.Category3Vo category3Vo = new Catelog2Vo.Category3Vo(categoryEntity2.getCatId().toString(), categoryEntity3.getCatId().toString(), categoryEntity3.getName());
                return category3Vo;
            }).collect(Collectors.toList());
            catelog2Vo.setCatalog3List(collect);
            return catelog2Vo;
        }).collect(Collectors.toList());
        return list;
    }));
    return map;
}
```



## 分布式锁解决缓存击穿

### 本地锁的问题

本地锁只能锁住当前进程，当某个微服务是集群时，集群有多少机器就会查多少次数据库

![image-20230316111047315](images/image-20230316111047315.png)

### 分布式锁基本原理

![image-20230316185656035](images/image-20230316185656035.png)

### 分布式锁演进1--问题:锁不能释放

![image-20230316190258552](images/image-20230316190258552.png)

代码演示:

```java
/**
 * redis分布式锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedisLock() {
    // 1. 占分布式锁, setnx("lock","1111")
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", "1111");
    if (lock){
        // 2. 加锁成功...执行业务
        // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)){
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
            return map;
        }

        // 2). 查询数据库
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();

        // 3). 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON",s);

        // 3. 删除锁, 由于没设置过期时间，如果正好在这之前机器断电，无法执行删除锁，会造成死锁
        redisTemplate.delete("lock");
        return catalogJsonFromDB;

    }else {
        // 4.加锁失败...重试, 休眠100ms重试
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return getCatalogJsonFromDBWithLocalLock(); // 自旋的方式
    }
}
```

### 分布式锁演进2--问题:设置锁与设置过期时间不是原子操作

![image-20230316192454993](images/image-20230316192454993.png)

代码演示:

```java
/**
 * redis分布式锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedisLock() {
    // 1. 占分布式锁, setnx("lock","1111")
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", "1111");
    if (lock){
        // 1.1设置过期时间
        redisTemplate.expire("lock",30, TimeUnit.SECONDS);
        // 2. 加锁成功...执行业务
        // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)){
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
            return map;
        }

        // 2). 查询数据库
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();

        // 3). 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON",s);

        // 3. 删除锁, 由于没设置过期时间，如果正好在这之前机器断电，无法执行删除锁，会造成死锁
        redisTemplate.delete("lock");
        return catalogJsonFromDB;

    }else {
        // 4.加锁失败...重试, 休眠100ms重试
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return getCatalogJsonFromDBWithLocalLock(); // 自旋的方式
    }
}
```

### 分布式锁演进3--问题:删除锁时删掉别人的锁

![image-20230316193028673](images/image-20230316193028673.png)

代码演示:

```java
/**
 * redis分布式锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedisLock() {
    // 1. 占分布式锁, setnxex("lock","1111",30s) 设置锁并设置过期时间保证原子操作
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", "1111", 30 , TimeUnit.SECONDS);
    if (lock){
        // 2. 加锁成功...执行业务
        // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)){
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
            return map;
        }

        // 2). 查询数据库
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();

        // 3). 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON",s);

        // 3. 删除锁, 由于没设置过期时间，如果正好在这之前机器断电，无法执行删除锁，会造成死锁
        redisTemplate.delete("lock");
        return catalogJsonFromDB;

    }else {
        // 4.加锁失败...重试, 休眠100ms重试
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return getCatalogJsonFromDBWithLocalLock(); // 自旋的方式
    }
}
```

### 分布式锁演进4--问题:查询锁的值与删除锁不是原子操作

![image-20230316193716571](images/image-20230316193716571.png)

代码演示:

```java
/**
 * redis分布式锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedisLock() {
    // 1. 占分布式锁, setnxex("lock","1111",30s) 设置锁并设置过期时间保证原子操作
    String uuid = UUID.randomUUID().toString();
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 30 , TimeUnit.SECONDS);
    if (lock){
        // 2. 加锁成功...执行业务
        // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)){
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {});
            return map;
        }

        // 2). 查询数据库
        Map<String, List<Catelog2Vo>> catalogJsonFromDB = getCatalogJsonFromDB();

        // 3). 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON",s);

        // 3. 删除锁, 由于没设置过期时间，如果正好在这之前机器断电，无法执行删除锁，会造成死锁
        // 判断是自己加的锁
        String lockValue = redisTemplate.opsForValue().get("lock");
        if (uuid.equals(lockValue)) {
            // 删除自己的锁
            redisTemplate.delete("lock");
        }
        return catalogJsonFromDB;

    }else {
        // 4.加锁失败...重试, 休眠100ms重试
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return getCatalogJsonFromDBWithLocalLock(); // 自旋的方式
    }
}
```

### 分布式锁演进5--最终方案--问题:锁没有自动续期

![image-20230316194051172](images/image-20230316194051172.png)

代码演示:

```java
/**
 * redis分布式锁
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedisLock() {
    // 1. 占分布式锁, setnxex("lock","1111",30s) 设置锁并设置过期时间保证原子操作
    String uuid = UUID.randomUUID().toString();
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 30, TimeUnit.SECONDS);

    if (lock) {
        // 2. 加锁成功...执行业务
        Map<String, List<Catelog2Vo>> catalogJsonFromDB;
        try {
            // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
            String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
            if (!StringUtils.isEmpty(catalogJSON)) {
                Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {
                });
                return map;
            }

            // 2). 查询数据库
            catalogJsonFromDB = getCatalogJsonFromDB();

            // 3). 从数据库中查到的数据存到redis中
            // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
            // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
            String s = JSON.toJSONString(catalogJsonFromDB);
            redisTemplate.opsForValue().set("catalogJSON", s);

        } finally {
            // 3. 删除锁, 由于没设置过期时间，如果正好在这之前机器断电，无法执行删除锁，会造成死锁
            // 判断是自己加的锁 + 删除锁 要保证原子操作
            String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
            redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
        }
        return catalogJsonFromDB;
    } else {
        // 4.加锁失败...重试, 休眠100ms重试
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return getCatalogJsonFromDBWithLocalLock(); // 自旋的方式
    }
}
```



## 分布式锁框架Redisson

### 可重入锁

如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改[Config.lockWatchdogTimeout](https://github.com/redisson/redisson/wiki/2.-配置方法#lockwatchdogtimeout监控锁的看门狗超时单位毫秒)来另行指定。

另外Redisson还通过加锁的方法提供了`leaseTime`的参数来指定加锁的时间。超过这个时间后锁便自动解开了。

```java
package com.imgyh.mall.product.test;

import org.redisson.api.RLock;
import org.redisson.api.RedissonClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.RestController;

import java.util.concurrent.TimeUnit;

@RestController
public class ProducttestController {
    @Autowired
    RedissonClient redisson;
    @ResponseBody
    @GetMapping("/test/redisson/lock")
    public String testRedisson(){
        //1、获取一把锁，只要锁的名字一样，就是同一把锁
        RLock myLock = redisson.getLock("my-lock");

        //2、加锁
        myLock.lock();      //阻塞式等待。默认加的锁都是30s
        //1）、锁的自动续期，如果业务超长，运行期间自动锁上新的30s。不用担心业务时间长，锁自动过期被删掉
        //2）、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认会在30s内自动过期，不会产生死锁问题

        // myLock.lock(10,TimeUnit.SECONDS);   //10秒钟自动解锁,自动解锁时间一定要大于业务执行时间
        //问题：在锁时间到了以后，不会自动续期

        //1、如果我们传递了锁的超时时间(myLock.lock(10,TimeUnit.SECONDS);)，就发送给redis执行脚本，进行占锁，默认超时就是 我们制定的时间
        //2、如果我们未指定锁的超时时间(myLock.lock(); )，就使用 lockWatchdogTimeout = 30 * 1000 【看门狗默认时间】
        //  只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】,每隔10秒都会自动的再次续期，续成30秒
        //  internalLockLeaseTime 【看门狗时间】 / 3， 10s

        // 推荐使用myLock.lock(10,TimeUnit.SECONDS); 省掉了续期操作。手动来解锁
        try {
            System.out.println("加锁成功，执行业务..." + Thread.currentThread().getId());
            try { TimeUnit.SECONDS.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); }
        } catch (Exception ex) {
            ex.printStackTrace();
        } finally {
            //3、解锁  假设解锁代码没有运行，Redisson会不会出现死锁
            System.out.println("释放锁..." + Thread.currentThread().getId());
            myLock.unlock();
        }

        return "redisson";
    }
}

```

### 读写锁--保证一定能读到最新数据

分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。

保证一定能读到最新数据，修改期间，写锁是一个排它锁（互斥锁、独享锁），读锁是一个共享锁

写锁没释放读锁必须等待

 * 读 + 读 ：相当于无锁，并发读，只会在Redis中记录好，所有当前的读锁。他们都会同时加锁成功
 * 写 + 读 ：必须等待写锁释放
 * 写 + 写 ：阻塞方式
 * 读 + 写 ：有读锁。写也需要等待

```java
package com.imgyh.mall.product.test;

import org.redisson.api.RLock;
import org.redisson.api.RReadWriteLock;
import org.redisson.api.RedissonClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.ValueOperations;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.RestController;

import java.util.UUID;
import java.util.concurrent.TimeUnit;

@RestController
public class ProducttestController {
    @Autowired
    RedissonClient redisson;
    @Autowired
    StringRedisTemplate stringRedisTemplate;
   
    /**
     * 保证一定能读到最新数据，修改期间，写锁是一个排它锁（互斥锁、独享锁），读锁是一个共享锁
     * 写锁没释放读锁必须等待
     * 读 + 读 ：相当于无锁，并发读，只会在Redis中记录好，所有当前的读锁。他们都会同时加锁成功
     * 写 + 读 ：必须等待写锁释放
     * 写 + 写 ：阻塞方式
     * 读 + 写 ：有读锁。写也需要等待
     * @return
     */
    @GetMapping(value = "/test/redisson/write")
    @ResponseBody
    public String writeValue() {
        String s = "";
        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        RLock rLock = readWriteLock.writeLock();
        try {
            //1、改数据加写锁，读数据加读锁
            rLock.lock();
            s = UUID.randomUUID().toString();
            ValueOperations<String, String> ops = stringRedisTemplate.opsForValue();
            ops.set("writeValue",s);
            TimeUnit.SECONDS.sleep(10);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            rLock.unlock();
        }

        return s;
    }

    @GetMapping(value = "/test/redisson/read")
    @ResponseBody
    public String readValue() {
        String s = "";
        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        //加读锁
        RLock rLock = readWriteLock.readLock();
        try {
            rLock.lock();
            ValueOperations<String, String> ops = stringRedisTemplate.opsForValue();
            s = ops.get("writeValue");
            try { TimeUnit.SECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            rLock.unlock();
        }

        return s;
    }

}

```

### 信号量

设置一个信号量(redis中键的名字=park), 获取一个信号表示信号量的值减1，释放一个信号量表示信号量加1。当信号量减为0或者redis中没有该信号量, 就获取不到信号，也不会执行减1操作。当redis中没有该信号量，释放一个信号会创建这个信号量并加1。

```
package com.imgyh.mall.product.test;

import org.redisson.api.RLock;
import org.redisson.api.RReadWriteLock;
import org.redisson.api.RSemaphore;
import org.redisson.api.RedissonClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.ValueOperations;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.RestController;

import java.util.UUID;
import java.util.concurrent.TimeUnit;

@RestController
public class ProducttestController {

    @Autowired
    RedissonClient redisson;
    @Autowired
    StringRedisTemplate stringRedisTemplate;

    /**
     * 车库停车
     * 3车位
     * 信号量也可以做分布式限流
     */
    @GetMapping(value = "/test/redisson/park")
    @ResponseBody
    public String park() throws InterruptedException {

        RSemaphore park = redisson.getSemaphore("park");
        // park.acquire();     //获取一个信号、计数减少1, 阻塞式
        boolean flag = park.tryAcquire(); // 尝试获取一个信号,获取到返回true, 没获取到返回false

        if (flag) {
            //执行业务
        } else {
            return "error";
        }

        return "ok=>" + flag;
    }

    @GetMapping(value = "/test/redisson/go")
    @ResponseBody
    public String go() {
        RSemaphore park = redisson.getSemaphore("park");
        park.release();     //释放一个信号, 计数增加1
        return "ok";
    }

}
```

### 闭锁

闭锁会设置一个初始数值，当调用countDown();把数减为0后删除锁, 这就表示闭锁完成了。await();就可以放行了。

```java
package com.imgyh.mall.product.test;

import org.redisson.api.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.ValueOperations;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.RestController;

import java.util.UUID;
import java.util.concurrent.TimeUnit;

@RestController

public class ProducttestController {

    @Autowired
    RedissonClient redisson;
    @Autowired
    StringRedisTemplate stringRedisTemplate;

    /**
     * 放假、锁门
     * 1班没人了
     * 5个班，全部走完，我们才可以锁大门
     * 分布式闭锁
     */

    @GetMapping(value = "/test/redisson/lockDoor")
    @ResponseBody
    public String lockDoor() throws InterruptedException {

        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5); // 设置一个初始数
        door.await();       //等待闭锁完成，当调用door.countDown();把数减为0后删除锁(redis中的door),这就表示闭锁完成了

        return "放假了...";
    }

    @GetMapping(value = "/test/redisson/gogogo/{id}")
    @ResponseBody
    public String gogogo(@PathVariable("id") Long id) {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.countDown();       //计数-1

        return id + "班的人都走了...";
    }

}

```



## 缓存一致性问题

我们系统的一致性解决方案：
1、缓存的所有数据都有过期时间，数据过期下一次查询触发主动更新
2、读写数据的时候，加上分布式的读写锁。

![image-20230318161515871](images/image-20230318161515871.png)

![image-20230318161548638](images/image-20230318161548638.png)

![image-20230318161605487](images/image-20230318161605487.png)

![image-20230318161624030](images/image-20230318161624030.png)

## 使用Redisson提供的分布式锁解决缓存击穿

我们系统的一致性解决方案：
1、缓存的所有数据都有**过期时间**，数据过期下一次查询触发主动更新
2、读写数据的时候，加上**分布式的读写锁**。

```java
/**
 * redisson分布式锁
 *
 * @return
 */
private Map<String, List<Catelog2Vo>> getCatalogJsonFromDBWithRedissonLock() {
    //1、占分布式锁。去redis占坑
    //（锁的粒度，越细越快:具体缓存的是某个数据，11号商品） product-11-lock
    //RLock catalogJsonLock = redissonClient.getLock("catalogJson-lock");
    //创建读锁
    RReadWriteLock readWriteLock = redissonClient.getReadWriteLock("catalogJson-lock");

    RLock rLock = readWriteLock.readLock();

    Map<String, List<Catelog2Vo>> catalogJsonFromDB;
    try {
        rLock.lock();
        // 2. 加锁成功...执行业务
        // 1). 拿到锁后再去缓存中查一次。如果大量请求都在等待锁释放, 拿到锁后, 如果不去缓存中再拿一次, 还是有大量请求去请求数据库
        String catalogJSON = redisTemplate.opsForValue().get("catalogJSON");
        if (!StringUtils.isEmpty(catalogJSON)) {
            Map<String, List<Catelog2Vo>> map = JSON.parseObject(catalogJSON, new TypeReference<Map<String, List<Catelog2Vo>>>() {
            });
            return map;
        }

        // 2). 查询数据库
        catalogJsonFromDB = getCatalogJsonFromDB();

        // 3). 从数据库中查到的数据存到redis中
        // 要锁到这里, 如果只锁到查询数据库完成, 在第一个请求查询完数据库，把数据放入缓存时会花费时间
        // 这段时间第二个请求拿到锁, 发现缓存中还是没有数据，又会再去查询数据库，这将增加一次查询数据库
        String s = JSON.toJSONString(catalogJsonFromDB);
        redisTemplate.opsForValue().set("catalogJSON", s);

    } finally {
        // 3. 删除锁
        rLock.unlock();
    }
    return catalogJsonFromDB;
}
```

## Spring-Cache使用

Spring 从3.1 开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager 接口来统一不同的缓存技术；并支持使用JCache（JSR-107）注解简化我们开发；

- Cache 接口为缓存的组件规范定义，包含缓存的各种操作集合；
- Cache 接口下Spring 提供了各种xxxCache 的实现； 如RedisCache ， EhCacheCache ,ConcurrentMapCache 等；
- 每次调用需要缓存功能的方法时，Spring 会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。
- 使用Spring 缓存抽象时我们需要关注以下两点；
  1、确定方法需要被缓存以及他们的缓存策略
  2、从缓存中读取之前缓存存储的数据

![image-20230318164913151](images/image-20230318164913151.png)

### 注解

https://docs.spring.io/spring-framework/docs/5.3.15/reference/html/integration.html#cache

```
@Cacheable：触发将数据保存到缓存的操作。

@CacheEvict: 触发将数据从缓存删除的操作。

@CachePut：在不干扰方法执行的情况下更新缓存。

@Caching：组合以上多个缓存操作。

@CacheConfig：在类级别共享一些常见的缓存相关设置。
```

![image-20230318172900353](images/image-20230318172900353.png)

![image-20230318172919791](images/image-20230318172919791.png)



### 表达式语法

![image-20230318172841544](images/image-20230318172841544.png)



### 简单使用

yml:

```yaml
spring:
  redis:
    host: 127.0.0.1
    port: 6379
  cache:
    type: redis # 使用redis作为缓存
    redis:
      time-to-live: 360000 #  过期时间，毫秒
#      key-prefix: Cache_ # key的前缀, 指定了前缀就用指定的前缀，没有指定就使用缓存的名字(注解中的value字段)作为前缀
      use-key-prefix: true # 是否使用前缀
      cache-null-values: true # 是否缓存空值，防止缓存穿透
```



#### @Cacheable

```java
@Cacheable(value = "category", key = "#root.method.name",sync = true) // 默认是无加锁的;使用sync = true来解决击穿问题 本地锁synchronized
@Override
public List<CategoryEntity> getLevel1Categorys() {
    List<CategoryEntity> categoryEntities = this.list(new QueryWrapper<CategoryEntity>().eq("parent_cid", 0));
    return categoryEntities;
}
```



1. 每一个需要缓存的数据我们都来指定要放到那个名字的缓存。【缓存的分区(按照业务类型分)】
2. 代表当前方法的结果需要缓存，如果缓存中有，方法都不用调用，如果缓存中没有，会调用方法。最后将方法的结果放入缓存
3. 默认行为
     1) 如果缓存中有，方法不再调用
     2) key是默认生成的:缓存的名字::SimpleKey::[] (自动生成key值)
     3) 缓存的value值，默认使用jdk序列化机制，将序列化的数据存到redis中
     4) 默认时间是 -1：
4. 自定义操作：key的生成
     1) 指定生成缓存的key：key属性指定，接收一个Spel表达式
     2) 指定缓存的数据的存活时间:配置文档中修改存活时间 spring.redis.time-to-live=36000 #毫秒
     3) 将数据保存为json格式

#### @CacheEvict、@Caching

@CacheEvict:失效模式
@CachePut:双写模式，需要有返回值
1、同时进行多种缓存操作：@Caching
2、指定删除某个分区下的所有数据 @CacheEvict(value = "category",allEntries = true)
3、存储同一类型的数据，都可以指定为同一分区

```java
/**
 * 级联更新所有关联的数据
 *
 * @param category
 */

// @Caching(evict = {
//         @CacheEvict(value = "category",key = "'getLevel1Categorys'"),
//         @CacheEvict(value = "category",key = "'getCatalogJson'")
// })
@CacheEvict(value = "category",allEntries = true)       //删除某个分区下的所有数据
@Transactional
@Override
public void updateAllRelatedTable(CategoryEntity category) {
    // 更新自己这张表
    this.updateById(category);
    // TODO 同步更新其他关联表中的数据
    if (!StringUtils.isEmpty(category.getName())) {
        categoryBrandRelationService.updateCatelogName(category.getCatId(), category.getName());
    }
}
```



### 将数据保存为json格式--自定义序列化

```java
package com.imgyh.mall.product.config;

import org.springframework.boot.autoconfigure.cache.CacheProperties;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.cache.RedisCacheConfiguration;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.RedisSerializationContext;
import org.springframework.data.redis.serializer.StringRedisSerializer;

@EnableConfigurationProperties(CacheProperties.class)
@Configuration
@EnableCaching
public class SpringCacheConfig {
    @Bean
    public RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) {

        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
        // config = config.entryTtl();
        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));

        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        //将配置文件中所有的配置都生效
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }

        return config;
    }

}

```



### Spring-Cache的不足之处

1. 读模式
    缓存穿透：查询一个null数据。解决方案：缓存空数据 spring.cache.redis.cache-null-values=true
    缓存击穿：大量并发进来同时查询一个正好过期的数据。解决方案：加锁 ? 默认是无加锁的;使用sync = true来解决击穿问题 本地锁synchronized，本地锁也就最多有该微服务的集群数量多个请求同时去查数据库，也不会很多
    缓存雪崩：大量的key同时过期。解决：加随机时间。解决方案：加上过期时间 spring.cache.redis.time-to-live=360000, 由于放入缓存的时间不同，设置固定的过期时间，也不会有大量key同时过期
2. 写模式：（缓存与数据库一致）
    1）、读写加锁。
    2）、引入Canal,感知到MySQL的更新去更新Redis
    3）、读多写多，直接去数据库查询就行

 总结：
     常规数据（读多写少，即时性，一致性要求不高的数据，完全可以使用Spring-Cache）：写模式(只要缓存的数据有过期时间就足够了)
     特殊数据：特殊设计
